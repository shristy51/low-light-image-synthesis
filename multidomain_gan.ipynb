{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44dad00-cf43-4510-a4ec-c594e5e7bd0e",
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1646519615629,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "d44dad00-cf43-4510-a4ec-c594e5e7bd0e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as KM\n",
    "import tensorflow.keras.layers as KL\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import glob\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Dropout, ReLU, Input, Concatenate, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d95f510-57f4-4e85-8474-1efb826324bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model,load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer,InputLayer, Input,Reshape, Conv2D, Conv2DTranspose,Embedding,Bidirectional,\\\n",
    "Dense, Flatten,BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, UpSampling2D,MaxPooling2D,Dropout,Concatenate,\\\n",
    "Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85db6874-fd35-4a88-8a0d-71183a246bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,RMSprop,Adadelta,SGD\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd1e4d2-4120-493e-adde-3d0e47aecdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6248b155-1115-4eb4-a638-79783852a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec11724-38da-43ac-88a7-33af1bcd2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num of GPUs available: \", len(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f4d905",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "error",
     "timestamp": 1646519635800,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "f1f09d7b-9321-4ffa-9b0e-ce75cdefda0d",
    "outputId": "6ebf8d3e-f14f-42b4-c9f8-ed870f2ef59d"
   },
   "outputs": [],
   "source": [
    "devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(devices[0] ,enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31889ebe-b70f-4051-95bc-e50253bd5f5f",
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1646519643707,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "31889ebe-b70f-4051-95bc-e50253bd5f5f"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d06c3e-dfbd-4a17-8f4a-917399ffdd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['2.5','3.0','3.5','4.0']\n",
    "data = [[0,1,2,3]]\n",
    "\n",
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Converting exposure labels to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee56bc6-ebd5-4fff-8346-c065e1c0492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = indices_to_one_hot(data,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39936dcd-4af2-4c71-9eb1-6044a4285587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "709ae45d-de3f-4c1a-b43d-5254823924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function reads the concatenated image and take input and real image separately\n",
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    w = tf.shape(image)[1]\n",
    "    w = w//2\n",
    "    real_image = image[:, :w, :]\n",
    "    input_image = image[:, w:, :]\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0704dabe-aef6-4d21-8a3f-7d3cf6816b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the images\n",
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 255)\n",
    "    real_image = (real_image / 255)\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d9cdb83-5f51-45de-991b-804b4f62a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the images to 512x512\n",
    "def resize(input_image, real_image):\n",
    "    input_image = tf.image.resize(input_image, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea1bb71-a6d0-49ea-8a07-68337c81d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_images(image_path):\n",
    "    input_image, real_image = load(image_path)\n",
    "    input_image, real_image = resize(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "    return input_image,real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "defc60d1-4f1c-406c-825d-a70178a58866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_image(image_path):\n",
    "    input_image, real_image = load(image_path)\n",
    "    input_image, real_image = resize(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ff1516-a320-4a21-a655-83014c17eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These folders consists of different folder for different exposures \n",
    "#Images in these folder are images created by concatenating Low light image with its corresponding normal light image\n",
    "\n",
    "path = \"rellisur_train_\"\n",
    "path_test = \"rellisur_test_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0653e4-7625-41d3-9aba-06797ec877bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we create corresponding labels for the images for training\n",
    "for i in range(len(one_hot)):\n",
    "    globals()[f\"train_dataset_{i}\"] = tf.data.Dataset.list_files(path + \"/train_\"+ label[i] + \"/*.png\")\n",
    "    globals()[f\"train_dataset_{i}\"]= globals()[f\"train_dataset_{i}\"].map(load_train_images)\n",
    "    globals()[f\"label_{i}\"]= np.full((len(globals()[f\"train_dataset_{i}\"]),4), one_hot[i])\n",
    "    globals()[f\"label_{i}\"]= tf.cast(globals()[f\"label_{i}\"], tf.int64)\n",
    "    globals()[f\"label_{i}\"]= tf.data.Dataset.from_tensor_slices(globals()[f\"label_{i}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e11c4aa-fda4-4256-9991-1dc0338ed2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_0.concatenate(train_dataset_1)\n",
    "train_dataset = train_dataset.concatenate(train_dataset_2)\n",
    "train_dataset = train_dataset.concatenate(train_dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c38c1bea-b0e5-431c-bb1e-ab604355b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = label_0.concatenate(label_1)\n",
    "train_label = train_label.concatenate(label_2)\n",
    "train_label = train_label.concatenate(label_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58b6f347-8773-48d7-97b0-6498e9c0ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_train_dataset = tf.data.Dataset.zip((train_dataset, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f49cdda-1a99-4bcd-aabe-6ff7310ed61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(one_hot)):\n",
    "    globals()[f\"test_dataset_{i}\"] = tf.data.Dataset.list_files(path_test + \"/test_\"+ label[i] + \"/*.png\")\n",
    "    globals()[f\"test_dataset_{i}\"]= globals()[f\"test_dataset_{i}\"].map(load_test_image)\n",
    "    globals()[f\"test_label_{i}\"]= np.full((len(globals()[f\"test_dataset_{i}\"]),4), one_hot[i])\n",
    "    globals()[f\"test_label_{i}\"]= tf.cast(globals()[f\"test_label_{i}\"], tf.int64)\n",
    "    globals()[f\"test_label_{i}\"]= tf.data.Dataset.from_tensor_slices(globals()[f\"test_label_{i}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4afd7262-9bf4-4b02-8077-8053287e02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset_0.concatenate(test_dataset_1)\n",
    "test_dataset = test_dataset.concatenate(test_dataset_2)\n",
    "test_dataset = test_dataset.concatenate(test_dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab7b276f-e7ca-4090-bfd5-607aef8966bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label_0.concatenate(test_label_1)\n",
    "test_label = test_label.concatenate(test_label_2)\n",
    "test_label = test_label.concatenate(test_label_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c44b3da-4170-4792-8fe6-57fe25eb0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_test_dataset_0 = tf.data.Dataset.zip((test_dataset_0, test_label_0))\n",
    "zip_test_dataset_1 = tf.data.Dataset.zip((test_dataset_1, test_label_1))\n",
    "zip_test_dataset_2 = tf.data.Dataset.zip((test_dataset_2, test_label_2))\n",
    "zip_test_dataset_3 = tf.data.Dataset.zip((test_dataset_3, test_label_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3998f74c-850a-454b-ba0d-9824a8aeeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are zipping the all the data to create a single dataset\n",
    "zip_test_dataset = tf.data.Dataset.zip((test_dataset, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e25973b4-7679-4fcb-8a52-81ea8c52be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_wise_concatenate(input_img, input_label):\n",
    "            # one hot vector is spatially replicated and concatenated with the input image\n",
    "            label = Lambda(lambda x: K.repeat(x, 512**2))(input_label)\n",
    "            label = Reshape((512, 512, 4))(label)\n",
    "            x = Concatenate()([input_img, label])  \n",
    "            return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66ef5eb7-a122-479d-84b0-5fc5a7048f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a part of the generator used to downsample the image\n",
    "def downsample(filters, size, batchnorm = True):\n",
    "    init = tf.random_normal_initializer(0.,0.02)\n",
    "    result = Sequential()\n",
    "    result.add(Conv2D(filters, size, strides = 2, padding = \"same\", kernel_initializer = init, use_bias = False))\n",
    "    if batchnorm == True:\n",
    "        result.add(BatchNormalization())\n",
    "        \n",
    "    result.add(LeakyReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98068134-9432-45f0-8dd9-c2e0052da296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, dropout = False):\n",
    "    init = tf.random_normal_initializer(0, 0.02)\n",
    "    result = Sequential()\n",
    "    result.add(Conv2DTranspose(filters, size, strides = 2, padding = \"same\", kernel_initializer = init, use_bias = False))\n",
    "    result.add(BatchNormalization())\n",
    "    if dropout == True:\n",
    "        result.add(Dropout(0.5))\n",
    "    result.add(ReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ce66012-7427-47d6-aea1-b7a329ca9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    inputs = Input(shape = [IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    label = Input(shape=(4,))\n",
    "    input = depth_wise_concatenate(inputs, label) \n",
    "    \n",
    "    down_stack = [\n",
    "        downsample(64, 4, batchnorm=False),\n",
    "        downsample(128, 4),\n",
    "        downsample(256, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    up_stack = [\n",
    "        upsample(512, 4, dropout=True),\n",
    "        upsample(512, 4, dropout=True),\n",
    "        upsample(512, 4),\n",
    "        upsample(512, 4),\n",
    "        upsample(256, 4),\n",
    "        upsample(128, 4),\n",
    "        upsample(64, 4),\n",
    "    ]\n",
    "    init = tf.random_normal_initializer(0., 0.02)\n",
    "    last = Conv2DTranspose(3, 4, strides = 2, padding = \"same\", kernel_initializer = init, activation =\"tanh\")\n",
    "    x = input\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    skips = reversed(skips[:-1])\n",
    "    \n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = Concatenate()([x, skip])\n",
    "    \n",
    "    x = last(x)\n",
    "    return Model(inputs = [inputs,label], outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f24d0e30-9139-47ad-9f23-92695624853c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 262144, 4)    0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 512, 512, 4)  0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512, 512, 7)  0           ['input_1[0][0]',                \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 256, 256, 64  7168        ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 128, 128, 12  131584      ['sequential[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 64, 64, 256)  525312      ['sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 32, 32, 512)  2099200     ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 16, 16, 512)  4196352     ['sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 8, 8, 512)    4196352     ['sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 4, 4, 512)    4196352     ['sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 2, 2, 512)    4196352     ['sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 4, 4, 512)    4196352     ['sequential_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4, 4, 1024)   0           ['sequential_8[0][0]',           \n",
      "                                                                  'sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 8, 8, 512)    8390656     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 1024)   0           ['sequential_9[0][0]',           \n",
      "                                                                  'sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 16, 16, 512)  8390656     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 1024  0           ['sequential_10[0][0]',          \n",
      "                                )                                 'sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 32, 32, 512)  8390656     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 1024  0           ['sequential_11[0][0]',          \n",
      "                                )                                 'sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 64, 64, 256)  4195328     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 512)  0           ['sequential_12[0][0]',          \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 128, 128, 12  1049088     ['concatenate_5[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 25  0           ['sequential_13[0][0]',          \n",
      "                                6)                                'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 256, 256, 64  262400      ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 12  0           ['sequential_14[0][0]',          \n",
      "                                8)                                'sequential[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 512, 512, 3)  6147       ['concatenate_7[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,429,955\n",
      "Trainable params: 54,419,075\n",
      "Non-trainable params: 10,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = generator()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9890d361-4f3c-438f-9698-62e9f2972c30",
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1646519857094,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "9890d361-4f3c-438f-9698-62e9f2972c30"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "loss_function = BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44c251c7-04d3-433d-a591-372f4fdf352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining vgg perceptual loss\n",
    "selected_layers = [\"block1_conv2\",\"block2_conv2\",\"block3_conv4\",\"block4_conv4\",\"block5_conv4\"]\n",
    "selected_layer_weights = [0.1,0.1,1.0,1.0,1.0]\n",
    "\n",
    "vgg = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(512,512,3))\n",
    "vgg.trainable = False\n",
    "outputs = [vgg.get_layer(l).output for l in selected_layers]\n",
    "model = Model(vgg.input, outputs)\n",
    "rc_loss = None\n",
    "\n",
    "@tf.function\n",
    "def perceptual_loss(target , gen_output):\n",
    "    h1_list = model(target)\n",
    "    h2_list = model(gen_output)\n",
    "    global rc_loss\n",
    "    if rc_loss is None:\n",
    "        rc_loss = 0.0\n",
    "    \n",
    "    for h1, h2, weight in zip(h1_list, h2_list, selected_layer_weights):\n",
    "        h1 = tf.keras.backend.batch_flatten(h1)\n",
    "        h2 = tf.keras.backend.batch_flatten(h2)\n",
    "        rc_loss = rc_loss + weight * tf.reduce_mean(tf.abs(h1 - h2), axis=-1)\n",
    "        #rc_loss = rc_loss + weight * tf.keras.backend.sum(tf.keras.backend.square(h1 - h2), axis=-1)\n",
    "\n",
    "    return rc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59828d-b2cd-46f9-974e-69e3d791c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_loss(logit, label) :\n",
    "    label= tf.cast(label, tf.float32)\n",
    "    loss=loss_function(label, logit)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "143dc416-a0fc-47d9-878c-e00cfcc5856e",
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1646519859176,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "143dc416-a0fc-47d9-878c-e00cfcc5856e"
   },
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target,Y_pred,target_label):\n",
    "    percep_loss = perceptual_loss(target, gen_output)[0]\n",
    "    gan_loss = loss_function(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    fake_c_loss = classification_loss(logit=Y_pred,label=target_label)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_gen_loss = (gan_loss) + 100*l1_loss + fake_c_loss + 10*percep_loss\n",
    "    return total_gen_loss, gan_loss, l1_loss,fake_c_loss,target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "842dba74-676c-461d-b86d-6725fa071df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_layer(layer_input, filters, f_size=4, strides=2,normalization=False):\n",
    "            \n",
    "            init = RandomNormal(stddev=0.02)\n",
    "\n",
    "            d_layer = ZeroPadding2D((1,1))(layer_input)\n",
    "            d_layer = Conv2D(filters, kernel_size=f_size, strides=strides, padding='valid',kernel_initializer=init)(d_layer)\n",
    "            if normalization:                \n",
    "                d_layer = InstanceNormalization(axis=-1)(d_layer)\n",
    "            d_layer = LeakyReLU(alpha=0.01)(d_layer)\n",
    "            return d_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48a81789-1e57-445d-a8cf-0a704b45e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "        inp = Input(shape = [IMAGE_SIZE, IMAGE_SIZE, 3], name = \"input_image\")\n",
    "        tar = Input(shape = [IMAGE_SIZE, IMAGE_SIZE, 3], name = \"target_image\")\n",
    "        x = Concatenate()([inp, tar])\n",
    "        \n",
    "        model = disc_layer(x, 64, normalization=False)\n",
    "        \n",
    "        model = disc_layer(model, 128)\n",
    "        model = disc_layer(model, 256)\n",
    "        model = disc_layer(model, 512)\n",
    "        model = disc_layer(model, 1024)\n",
    "        model = disc_layer(model, 2048)        \n",
    "        \n",
    "        \n",
    "\n",
    "        output_d_src = ZeroPadding2D((1,1))(model)\n",
    "\n",
    "        output_d_src = Conv2D(1, kernel_size=3, strides=1, padding='valid')(output_d_src)\n",
    "        \n",
    "\n",
    "        model = Conv2D(filters =4,kernel_size = int(512/64), strides = 1,padding = 'valid')(model)      \n",
    "\n",
    "        \n",
    "        output_d_cls = Reshape((4,))(model)\n",
    "        output_d_cls = tf.nn.softmax(output_d_cls)\n",
    "        \n",
    "        return Model(inputs = [inp, tar], outputs = [output_d_src,output_d_cls])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba2a092c-8a2d-44a5-a9df-a54e81ac47dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " target_image (InputLayer)      [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 512, 512, 6)  0           ['input_image[0][0]',            \n",
      "                                                                  'target_image[0][0]']           \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 514, 514, 6)  0          ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 64  6208        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 256, 256, 64  0           ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 258, 258, 64  0          ['leaky_re_lu_8[0][0]']          \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 12  131200      ['zero_padding2d_1[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 128, 128, 12  0           ['conv2d_9[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 130, 130, 12  0          ['leaky_re_lu_9[0][0]']          \n",
      " D)                             8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 256)  524544      ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 64, 64, 256)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 66, 66, 256)  0          ['leaky_re_lu_10[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2097664     ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 32, 32, 512)  0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 34, 34, 512)  0          ['leaky_re_lu_11[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 1024  8389632     ['zero_padding2d_4[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 16, 16, 1024  0           ['conv2d_12[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 18, 18, 1024  0          ['leaky_re_lu_12[0][0]']         \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 2048)   33556480    ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 8, 8, 2048)   0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 1, 4)      524292      ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, 10, 10, 2048  0          ['leaky_re_lu_13[0][0]']         \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 4)            0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 1)      18433       ['zero_padding2d_6[0][0]']       \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 4)            0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,248,453\n",
      "Trainable params: 45,248,453\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = discriminator()\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd343af5-6547-49f9-9206-074525b7e47d",
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1646519868209,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "cd343af5-6547-49f9-9206-074525b7e47d"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output,Y_true,target_label):\n",
    "    real_loss = loss_function(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = loss_function(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    real_c_loss = classification_loss(logit=Y_true,label=target_label)\n",
    "    total_disc_loss = real_loss + generated_loss + real_c_loss\n",
    "    return total_disc_loss,real_c_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40831495-aad8-4cb9-a9d1-c1eb5f65a1c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1646519870099,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "40831495-aad8-4cb9-a9d1-c1eb5f65a1c0",
    "outputId": "0c9676b8-fd81-4579-b5e5-6be4b326a4b4"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(lr= 1e-4, beta_1=0.5,clipvalue=0.5)\n",
    "discriminator_optimizer = Adam(lr = 1e-8, beta_1=0.5,clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbb509b9-e391-474a-bd9b-0eaf2d60e318",
   "metadata": {
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1646519947443,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "bbb509b9-e391-474a-bd9b-0eaf2d60e318"
   },
   "outputs": [],
   "source": [
    "def save_images(model, test_input, target,label, epoch,exposure):\n",
    "    prediction = model([test_input,label], training= True)\n",
    "    gen.save('generator.h5')\n",
    "    disc.save('discriminator.h5')\n",
    "    if epoch%3==0:\n",
    "        print(label)\n",
    "        tf.keras.preprocessing.image.save_img(f\"input_{epoch}_{exposure}.png\",test_input[0])\n",
    "        tf.keras.preprocessing.image.save_img(f\"target_{epoch}_{exposure}.png\",target[0])\n",
    "        tf.keras.preprocessing.image.save_img(f\"output_{epoch}_{exposure}.png\",prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81cefd03-96a2-49a5-bed2-f84cfa142d47",
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1646519950899,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "81cefd03-96a2-49a5-bed2-f84cfa142d47"
   },
   "outputs": [],
   "source": [
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ae0f44f-320c-48ad-9e28-3dbad019ea07",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1646519952178,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "1ae0f44f-320c-48ad-9e28-3dbad019ea07"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image,target,target_label, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = gen([input_image,target_label], training = True)\n",
    "        disc_real_output,Y_true = disc([input_image, target], training = True)\n",
    "        disc_generated_output,Y_pred = disc([input_image, gen_output], training = True)\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss,gcloss,target_label = generator_loss(disc_generated_output, gen_output, target,Y_pred,target_label)\n",
    "        disc_loss, classification_loss = discriminator_loss(disc_real_output, disc_generated_output,Y_true,target_label)\n",
    "        generator_gradients = gen_tape.gradient(gen_total_loss, gen.trainable_variables)\n",
    "        discriminator_gradients = disc_tape.gradient(disc_loss, disc.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(generator_gradients, gen.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, disc.trainable_variables))\n",
    "        return gen_total_loss, disc_loss ,Y_true,Y_pred,gcloss,classification_loss,target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06538f20-7c54-4013-8dd3-9c43915a9ef6",
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1646519954140,
     "user": {
      "displayName": "shristy shah",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZF6VmtUMZ65B-RMtxI_dY8LXkH6MOB3YdZdfSug=s64",
      "userId": "16393959611633468075"
     },
     "user_tz": -60
    },
    "id": "06538f20-7c54-4013-8dd3-9c43915a9ef6"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(30,epochs):\n",
    "        start = time.time()\n",
    "        for input_t, label in zip_test_dataset_0.take(1):\n",
    "            input_np = np.array(input_t)\n",
    "            target = input_np[1:2,:,:,:]\n",
    "            input_ =input_np[0:1,:,:,:]\n",
    "            target = tf.cast(target, tf.float32)\n",
    "            input_ = tf.cast(input_, tf.float32)\n",
    "            label =tf.reshape(label, [1, 4])\n",
    "            save_images(gen, input_, target,label, epoch,2.5)\n",
    "        for input_t, label in zip_test_dataset_1.take(1):\n",
    "            input_np = np.array(input_t)\n",
    "            target = input_np[1:2,:,:,:]\n",
    "            input_ =input_np[0:1,:,:,:]\n",
    "            target = tf.cast(target, tf.float32)\n",
    "            input_ = tf.cast(input_, tf.float32)\n",
    "            label =tf.reshape(label, [1, 4])\n",
    "            save_images(gen, input_, target,label, epoch,3.0)\n",
    "        for input_t, label in zip_test_dataset_2.take(1):\n",
    "            input_np = np.array(input_t)\n",
    "            target = input_np[1:2,:,:,:]\n",
    "            input_ =input_np[0:1,:,:,:]\n",
    "            target = tf.cast(target, tf.float32)\n",
    "            input_ = tf.cast(input_, tf.float32)\n",
    "            label =tf.reshape(label, [1, 4])\n",
    "            save_images(gen, input_, target,label, epoch,3.5)\n",
    "        for input_t, label in zip_test_dataset_3.take(1):\n",
    "            input_np = np.array(input_t)\n",
    "            target = input_np[1:2,:,:,:]\n",
    "            input_ =input_np[0:1,:,:,:]\n",
    "            target = tf.cast(target, tf.float32)\n",
    "            input_ = tf.cast(input_, tf.float32)\n",
    "            label =tf.reshape(label, [1, 4])\n",
    "            save_images(gen, input_, target,label, epoch,4.0)      \n",
    "        print(f\"Epoch {epoch}\")\n",
    "        for n, (input_t, label) in train_ds.enumerate():\n",
    "            input_np = np.array(input_t)\n",
    "            target = input_np[1:2,:,:,:]\n",
    "            input_ =input_np[0:1,:,:,:]\n",
    "            target = tf.cast(target, tf.float32)\n",
    "            input_ = tf.cast(input_, tf.float32)\n",
    "            label =tf.reshape(label, [1, 4])\n",
    "            gen_loss, disc_loss,Y_true,Y_pred,gcloss,classification_loss,target_label = train_step(input_, target,label, epoch)\n",
    "        print(\"Generator loss {:.2f} Discriminator loss {:.2f}\".format(gen_loss, disc_loss))\n",
    "        print(\"Time take for epoch {} is {} sec\\n\".format(epoch+1, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67edbe2b-4b57-43e7-864b-46e275d0c039",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67edbe2b-4b57-43e7-864b-46e275d0c039",
    "outputId": "e802fd3b-3681-43e7-c332-df6b63447b34"
   },
   "outputs": [],
   "source": [
    "fit(zip_train_dataset, epochs, zip_test_dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pix2pix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
